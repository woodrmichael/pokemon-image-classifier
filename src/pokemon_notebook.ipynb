{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Your Model\n",
    "In this exercise, we'll expose new images to our model and see how it does"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Model\n",
    "Let's load the saved model that we trained. Modify the code below to point to the model you select.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import horovod.keras as hvd\n",
    "from keras import backend as K\n",
    "import keras.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that you will need to update this model name \n",
    "model = keras.models.load_model('YOURMODELNAMEHERE.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to, you can see the summary of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing the Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use our model to make predictions on new images, it will be useful to show the image as well. We can use the matplotlib library to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def show_image(image_path):\n",
    "    image = mpimg.imread(image_path)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment the lines below to see a few of the testing set images\n",
    "#Can change to pokemon images\n",
    "\n",
    "# show_image('/data/cs2300/L9/fruits/test/freshapples/Screen Shot 2018-06-08 at 4.59.44 PM.png')\n",
    "# show_image('/data/cs2300/L9/fruits/test/freshbanana/Screen Shot 2018-06-12 at 9.49.00 PM.png')\n",
    "# show_image('/data/cs2300/L9/fruits/test/freshoranges/Screen Shot 2018-06-12 at 11.56.55 PM.png')\n",
    "# show_image('/data/cs2300/L9/fruits/test/rottenapples/Screen Shot 2018-06-07 at 2.15.34 PM.png')\n",
    "# show_image('/data/cs2300/L9/fruits/test/rottenbanana/Screen Shot 2018-06-12 at 9.28.04 PM.png')\n",
    "# show_image('/data/cs2300/L9/fruits/train/rottenoranges/Screen Shot 2018-06-12 at 11.47.08 PM.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images in our dataset were 224x224 pixels. We need to make sure to pass the same size images into our method for prediction. There are a few ways to edit images with Python, but Keras has a built-in utility that works well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "def load_and_scale_image(image_path):\n",
    "    image = image_utils.load_img(image_path, target_size=(224,224))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_and_scale_image('../data/Abra/00000000.png')\n",
    "# image = load_and_scale_image('../data/Alakazam/.png')\n",
    "# image = load_and_scale_image('../data/.png')\n",
    "# image = load_and_scale_image('../data/.png')\n",
    "# image = load_and_scale_image('../data/.png')\n",
    "# image = load_and_scale_image('../data/.png')\n",
    "plt.axis('off')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Image for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the right size image, we're close to being ready to pass it into our model for prediction. First we need to reshape our image to match the shape of the dataset the model was trained on. Before we can reshape, we need to convert our image into a more rudimentary format. We'll do this with a keras utility called image_to_array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image_utils.img_to_array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original image shape: {image.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can reshape our image and scale it (preprocess) to get it ready for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "image = preprocess_input(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "Okay, now we're ready to predict! This is done by passing our pre-processed image into the model's predict method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(image)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions are in the format of a length 6 array. Each element of the array is a probability between 0 and 1, representing the confidence for each category. Let's make it a little more readable. We can start by finding which element of the array represents the highest probability. Fill in the following cell using numpy to find the largest value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the path to the 'data' folder in the parent directory\n",
    "data_path = \"../data\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(data_path) and os.path.isdir(data_path):\n",
    "    # Get all folder names in the specified path\n",
    "    folders = [folder for folder in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, folder))]\n",
    "    \n",
    "    # Create a dictionary with incremental keys starting from 1\n",
    "    dictionary = {index + 1: folder for index, folder in enumerate(sorted(folders))}\n",
    "    \n",
    "    # Print the resulting dictionary\n",
    "    print()\n",
    "    \n",
    "else:\n",
    "    print(f\"Directory {data_path} does not exist or is not accessible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass in our prediction index to find the corresponding letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we demonstrate how to find all the files in a directory that match a given pattern (png images).  For each of the 6 classes (e.g., apple, rotten apple, etc.) in our testing data set, alter the code below to calculate the accuracy of your model on that class. Report the accuracy per class along with the total number of images in the testing set for that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "os.chdir('../data/Abra')\n",
    "totalImageCount = 0\n",
    "correctFruit = 0\n",
    "correctFruitTotal = 0\n",
    "for file in glob.glob('*.png'):\n",
    "    totalImageCount += 1\n",
    "    image = load_and_scale_image(file)\n",
    "    image = image_utils.img_to_array(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    prediction = model.predict(image)\n",
    "    if np.argmax(prediction) == correctFruit:\n",
    "        correctFruitTotal += 1\n",
    "    print(dictionary[np.argmax(prediction)])\n",
    "    \n",
    "print(\"Number of Total Images: \"+str(totalImageCount))\n",
    "print(\"Number of Correct Predictions: \"+str(correctFruitTotal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
